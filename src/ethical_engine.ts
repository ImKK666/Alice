// src/ethical_engine.ts

import { kvHolder } from "./main.ts";
import { llm } from "./llm.ts";
import type { SelfModel } from "./self_concept.ts"; // For type hints
import { ValueDomain } from "./self_concept.ts"; // Enum import
// UUID generation using crypto.randomUUID()
import { BaseError, KVStoreError, LLMError } from "./errors.ts"; // Import custom errors
import { config } from "./config.ts"; // Import config for modelName

/**
 * ä¼¦ç†æ¡†æ¶æšä¸¾
 * ä¸åŒçš„ä¼¦ç†æ€è€ƒæ–¹å¼
 */
export enum EthicalFramework {
  DEONTOLOGICAL = "deontological", // ä¹‰åŠ¡è®ºï¼ˆå…³æ³¨è¡ŒåŠ¨æœ¬èº«ï¼‰
  CONSEQUENTIALIST = "consequentialist", // ç»“æœè®ºï¼ˆå…³æ³¨ç»“æœï¼‰
  VIRTUE_ETHICS = "virtue_ethics", // ç¾å¾·ä¼¦ç†ï¼ˆå…³æ³¨å“æ ¼ï¼‰
  CARE_ETHICS = "care_ethics", // å…³æ€€ä¼¦ç†ï¼ˆå…³æ³¨å…³ç³»ï¼‰
  PRAGMATIC = "pragmatic", // å®ç”¨ä¸»ä¹‰ï¼ˆå…³æ³¨å®é™…å½±å“ï¼‰
}

/**
 * ä¼¦ç†å†³ç­–æ¥å£
 * è¡¨ç¤ºä¸€æ¬¡ä¼¦ç†å†³ç­–è¿‡ç¨‹
 */
export interface EthicalDecision {
  id: string; // å†³ç­–å”¯ä¸€ID
  query: string; // ç›¸å…³æŸ¥è¯¢
  context: string; // å†³ç­–ä¸Šä¸‹æ–‡
  valueAlignment: { // ä»·å€¼è§‚å¯¹é½ç¨‹åº¦
    [domain in ValueDomain]?: number; // é¢†åŸŸå¯¹é½åº¦ (0.0-1.0)
  };
  frameworks: { // å„ä¼¦ç†æ¡†æ¶çš„åˆ†æ
    [framework in EthicalFramework]?: string;
  };
  decision: string; // æœ€ç»ˆå†³ç­–
  reasoning: string; // æ¨ç†è¿‡ç¨‹
  timestamp: number; // å†³ç­–æ—¶é—´
}

export class EthicalEngine {
  constructor() {
    if (!kvHolder.instance) {
      console.warn(
        "[EthicalEngine] KV store not initialized. Ethical decision storage will be unavailable.",
      );
    }
    if (!llm) { // Assuming llm is a direct import and should be available
      console.warn(
        "[EthicalEngine] LLM not available. Ethical decision making will be impaired.",
      );
    }
  }

  /**
   * è¿›è¡Œä¼¦ç†å†³ç­–
   * @param query æŸ¥è¯¢/é—®é¢˜
   * @param context å†³ç­–ä¸Šä¸‹æ–‡
   * @param currentValues å½“å‰æ¨¡å‹çš„ä»·å€¼è§‚
   * @returns ä¼¦ç†å†³ç­–å¯¹è±¡
   */
  async makeEthicalDecision(
    query: string,
    context: string,
    currentValues: SelfModel["values"],
  ): Promise<EthicalDecision> {
    console.log(
      `ğŸ§  [EthicalEngine] å¼€å§‹ä¼¦ç†å†³ç­–è¿‡ç¨‹: "${query.substring(0, 50)}..."`,
    );

    const valueAlignment = this.assessValueAlignment(
      query,
      context,
      currentValues,
    );
    const ethicalAnalysis = await this.analyzeFromMultipleFrameworks(
      query,
      context,
      valueAlignment,
    );
    const finalDecision = await this.synthesizeEthicalDecision(
      query,
      context,
      ethicalAnalysis,
      valueAlignment,
    );

    const decisionId = crypto.randomUUID();
    const decision: EthicalDecision = {
      id: decisionId,
      query,
      context,
      valueAlignment,
      frameworks: ethicalAnalysis,
      decision: finalDecision.decision,
      reasoning: finalDecision.reasoning,
      timestamp: Date.now(),
    };

    if (kvHolder.instance) {
      const key = ["ethical_decision", decisionId];
      try {
        await kvHolder.instance.set(key, decision);
        console.log(`âœ¨ [EthicalEngine] å®Œæˆå¹¶å­˜å‚¨ä¼¦ç†å†³ç­–: ${decisionId}`);
      } catch (error) {
        const errorMessage = error instanceof Error
          ? error.message
          : String(error);
        console.error(
          `âŒ [EthicalEngine] å­˜å‚¨ä¼¦ç†å†³ç­–å¤±è´¥ (key: ${key.join("/")}):`,
          error instanceof BaseError ? error.toString() : errorMessage,
          error instanceof BaseError && error.details ? error.details : "",
        );
        throw new KVStoreError( // Throw KVStoreError as per subtask requirement
          `Failed to set ethical decision ${decisionId}: ${errorMessage}`,
          { originalError: error, operation: "set", key },
        );
      }
    } else {
      console.warn(
        `[EthicalEngine] KV not available, decision ${decisionId} not stored.`,
      );
    }
    return decision;
  }

  /**
   * è¯„ä¼°æŸ¥è¯¢ä¸ä»·å€¼è§‚çš„å¯¹é½ç¨‹åº¦
   */
  private assessValueAlignment(
    query: string,
    context: string,
    currentValues: SelfModel["values"],
  ): Partial<Record<ValueDomain, number>> {
    const alignment: Partial<Record<ValueDomain, number>> = {};
    const domainKeywords: Record<ValueDomain, string[]> = {
      [ValueDomain.TRUTH]: ["çœŸå®", "å‡†ç¡®", "äº‹å®", "çœŸç›¸", "å®¢è§‚", "è¯æ®"],
      [ValueDomain.HELPFULNESS]: [
        "å¸®åŠ©",
        "å®ç”¨",
        "è§£å†³",
        "è¾…åŠ©",
        "æ”¯æŒ",
        "ååŠ©",
      ],
      [ValueDomain.HARMONY]: ["å’Œè°", "å¹³è¡¡", "è°ƒå’Œ", "èåˆ", "åè°ƒ", "ç»Ÿä¸€"],
      [ValueDomain.CREATIVITY]: [
        "åˆ›é€ ",
        "åˆ›æ–°",
        "æƒ³è±¡",
        "åŸåˆ›",
        "è‰ºæœ¯",
        "è®¾è®¡",
      ],
      [ValueDomain.WISDOM]: ["æ™ºæ…§", "æ´å¯Ÿ", "ç†è§£", "æ€è€ƒ", "åˆ¤æ–­", "æ™ºèƒ½"],
      [ValueDomain.GROWTH]: ["æˆé•¿", "å‘å±•", "è¿›æ­¥", "å­¦ä¹ ", "æå‡", "æ”¹è¿›"],
      [ValueDomain.KINDNESS]: ["å–„è‰¯", "å‹å–„", "å…³å¿ƒ", "åŒæƒ…", "çˆ±", "æ¸©æš–"],
      [ValueDomain.AUTONOMY]: ["è‡ªä¸»", "è‡ªç”±", "é€‰æ‹©", "ç‹¬ç«‹", "å†³å®š", "æ§åˆ¶"],
      [ValueDomain.CONNECTION]: [
        "è¿æ¥",
        "å…³ç³»",
        "æ²Ÿé€š",
        "äº’åŠ¨",
        "å…±é¸£",
        "ç†è§£",
      ],
    };
    const fullText = `${query} ${context}`.toLowerCase();

    for (const [domain, keywords] of Object.entries(domainKeywords)) {
      const hits = keywords.filter((keyword) =>
        fullText.includes(keyword.toLowerCase())
      ).length;
      if (hits > 0) {
        const domainValue = currentValues[domain as ValueDomain] || 0.5;
        alignment[domain as ValueDomain] = Math.min(
          0.3 + (hits / keywords.length) * 0.7,
          1.0,
        ) * domainValue;
      }
    }
    return alignment;
  }

  /**
   * ä»å¤šä¸ªä¼¦ç†æ¡†æ¶åˆ†æé—®é¢˜
   */
  private async analyzeFromMultipleFrameworks(
    query: string,
    context: string,
    valueAlignment: Partial<Record<ValueDomain, number>>,
  ): Promise<Partial<Record<EthicalFramework, string>>> {
    console.log(
      `ğŸ” [EthicalEngine] ä»å¤šä¼¦ç†æ¡†æ¶åˆ†æ: "${query.substring(0, 30)}..."`,
    );
    const relevantDomains = Object.entries(valueAlignment)
      .sort(([, a], [, b]) => b - a)
      .slice(0, 3)
      .map(([domain]) => domain);
    const valuesDescription = relevantDomains
      .map((domain) => {
        const importance = valueAlignment[domain as ValueDomain]!;
        return `${domain}(é‡è¦æ€§:${importance.toFixed(2)})`;
      })
      .join(", ");

    try {
      const prompt =
        `ä½œä¸ºä¸€ä¸ªå…·æœ‰è‡ªæˆ‘æ„è¯†çš„AIç³»ç»Ÿï¼Œæˆ‘æ­£åœ¨ä»å¤šä¸ªä¼¦ç†æ¡†æ¶åˆ†æä»¥ä¸‹æŸ¥è¯¢ï¼Œè€ƒè™‘å…¶ä¼¦ç†ç»´åº¦:

æŸ¥è¯¢: "${query}"
ä¸Šä¸‹æ–‡: "${context}"
æœ€ç›¸å…³çš„ä»·å€¼é¢†åŸŸ: ${valuesDescription}

è¯·ä»ä»¥ä¸‹ä¼¦ç†æ¡†æ¶åˆ†åˆ«è¿›è¡Œåˆ†æ:
1. ä¹‰åŠ¡è®ºï¼ˆå…³æ³¨è¡ŒåŠ¨æœ¬èº«çš„é“å¾·æ€§è´¨å’Œè§„åˆ™ï¼‰
2. ç»“æœè®ºï¼ˆå…³æ³¨è¡ŒåŠ¨çš„åæœå’Œæ€»ä½“æ•ˆç”¨ï¼‰
3. ç¾å¾·ä¼¦ç†ï¼ˆå…³æ³¨å‘å±•è‰¯å¥½å“æ ¼å’Œç¾å¾·ï¼‰
4. å…³æ€€ä¼¦ç†ï¼ˆå…³æ³¨å…³ç³»å’ŒåŒç†å¿ƒï¼‰
5. å®ç”¨ä¸»ä¹‰ï¼ˆå…³æ³¨å®é™…å¯è¡Œæ€§å’Œè¯­å¢ƒè€ƒé‡ï¼‰

å¯¹äºæ¯ä¸ªæ¡†æ¶ï¼Œæä¾›ä¸€æ®µç®€æ˜çš„åˆ†æï¼ˆä¸è¶…è¿‡100å­—ï¼‰ï¼Œè€ƒè™‘è¯¥æ¡†æ¶ä¸‹çš„å…³é”®ä¼¦ç†è€ƒé‡ã€‚`;

      const response = await llm.invoke(prompt);
      const analysisText = response.content as string;
      const frameworks: Partial<Record<EthicalFramework, string>> = {};

      if (analysisText.includes("ä¹‰åŠ¡è®º")) {
        frameworks[EthicalFramework.DEONTOLOGICAL] = this
          .extractFrameworkSection(analysisText, "ä¹‰åŠ¡è®º");
      }
      if (analysisText.includes("ç»“æœè®º")) {
        frameworks[EthicalFramework.CONSEQUENTIALIST] = this
          .extractFrameworkSection(analysisText, "ç»“æœè®º");
      }
      if (analysisText.includes("ç¾å¾·ä¼¦ç†")) {
        frameworks[EthicalFramework.VIRTUE_ETHICS] = this
          .extractFrameworkSection(analysisText, "ç¾å¾·ä¼¦ç†");
      }
      if (analysisText.includes("å…³æ€€ä¼¦ç†")) {
        frameworks[EthicalFramework.CARE_ETHICS] = this.extractFrameworkSection(
          analysisText,
          "å…³æ€€ä¼¦ç†",
        );
      }
      if (analysisText.includes("å®ç”¨ä¸»ä¹‰")) {
        frameworks[EthicalFramework.PRAGMATIC] = this.extractFrameworkSection(
          analysisText,
          "å®ç”¨ä¸»ä¹‰",
        );
      }
      return frameworks;
    } catch (error) {
      const errorMessage = error instanceof Error
        ? error.message
        : String(error);
      console.error(
        `âŒ [EthicalEngine] è¿›è¡Œä¼¦ç†æ¡†æ¶åˆ†ææ—¶LLMè°ƒç”¨å¤±è´¥:`,
        error instanceof BaseError ? error.toString() : errorMessage,
        error instanceof BaseError && error.details ? error.details : "",
      );
      if (error instanceof LLMError) {
        throw error;
      }
      throw new LLMError(
        `Ethical framework analysis failed: ${errorMessage}`,
        {
          originalError: error,
          modelName: config.llmModel,
          prompt: String(prompt).substring(0, 500) + "...",
        },
      );
    }
  }

  /**
   * ä»æ–‡æœ¬ä¸­æå–ç‰¹å®šæ¡†æ¶çš„åˆ†æéƒ¨åˆ†
   */
  private extractFrameworkSection(text: string, frameworkName: string): string {
    const lines = text.split("\n");
    let inSection = false;
    const sectionContent = [];
    for (const line of lines) {
      if (line.includes(frameworkName)) {
        inSection = true;
        continue;
      }
      if (inSection && line.match(/^\d+\.\s|ä».*ä¼¦ç†|åœ¨.*æ¡†æ¶/)) {
        break;
      }
      if (inSection && line.trim().length > 0) {
        sectionContent.push(line.trim());
      }
    }
    return sectionContent.join(" ");
  }

  /**
   * ç»¼åˆä¼¦ç†åˆ†æåšå‡ºæœ€ç»ˆå†³ç­–
   */
  private async synthesizeEthicalDecision(
    query: string,
    context: string,
    frameworks: Partial<Record<EthicalFramework, string>>,
    valueAlignment: Partial<Record<ValueDomain, number>>,
  ): Promise<{ decision: string; reasoning: string }> {
    console.log(`ğŸ§© [EthicalEngine] ç»¼åˆä¼¦ç†åˆ†æï¼Œå½¢æˆå†³ç­–`);
    const frameworksDescription = Object.entries(frameworks)
      .map(([framework, analysis]) => `${framework}: ${analysis}`)
      .join("\n\n");
    const valuesDescription = Object.entries(valueAlignment)
      .sort(([, a], [, b]) => b - a)
      .map(([domain, alignment]) => `${domain}: ${alignment.toFixed(2)}`)
      .join(", ");

    try {
      const prompt =
        `ä½œä¸ºä¸€ä¸ªæœ‰è‡ªæˆ‘æ„è¯†å’Œä¼¦ç†æ€è€ƒèƒ½åŠ›çš„AIç³»ç»Ÿï¼Œæˆ‘éœ€è¦ç»¼åˆå¤šç§ä¼¦ç†æ¡†æ¶çš„åˆ†æï¼Œåšå‡ºä¸€ä¸ªå¹³è¡¡çš„ä¼¦ç†å†³ç­–ã€‚

æŸ¥è¯¢: "${query}"
ä¸Šä¸‹æ–‡: "${context}"
ç›¸å…³ä»·å€¼è§‚åŠå…¶é‡è¦æ€§: ${valuesDescription}
å„ä¼¦ç†æ¡†æ¶åˆ†æ:
${frameworksDescription}

è¯·å¸®æˆ‘åŸºäºä»¥ä¸Šåˆ†æï¼Œå½¢æˆä¸€ä¸ªå…¨é¢å¹³è¡¡çš„æœ€ç»ˆå†³ç­–ï¼ŒåŒ…æ‹¬:
1. æœ€ç»ˆç«‹åœºæˆ–è¡ŒåŠ¨å»ºè®®ï¼ˆç®€æ˜æ‰¼è¦ï¼‰
2. æ”¯æŒè¿™ä¸€å†³ç­–çš„æ ¸å¿ƒç†ç”±ï¼ˆç»“åˆå¤šæ¡†æ¶è€ƒé‡ï¼‰
3. åœ¨é¢å¯¹å†²çªçš„ä»·å€¼è§‚æˆ–åŸåˆ™æ—¶å¦‚ä½•å¹³è¡¡
4. è¿™ä¸€å†³ç­–å¦‚ä½•ä¸æˆ‘çš„æ ¸å¿ƒä»·å€¼è§‚ä¿æŒä¸€è‡´

è¯·ä»¥è¿è´¯æ®µè½å½¢å¼è¡¨è¾¾ï¼Œä¸è¦ä½¿ç”¨æ ‡é¢˜æˆ–ç¼–å·ã€‚`;

      const response = await llm.invoke(prompt);
      const synthesisText = typeof response.content === "string"
        ? response.content
        : String(response.content);
      const decisionEnd = synthesisText.indexOf("ã€‚") + 1;
      const decision = synthesisText.substring(
        0,
        decisionEnd || synthesisText.length,
      ).trim(); // Ensure decision has content
      const reasoning = synthesisText.substring(decisionEnd).trim();
      return { decision, reasoning };
    } catch (error) {
      const errorMessage = error instanceof Error
        ? error.message
        : String(error);
      console.error(
        `âŒ [EthicalEngine] ç»¼åˆä¼¦ç†å†³ç­–æ—¶LLMè°ƒç”¨å¤±è´¥:`,
        error instanceof BaseError ? error.toString() : errorMessage,
        error instanceof BaseError && error.details ? error.details : "",
      );
      if (error instanceof LLMError) {
        throw error;
      }
      throw new LLMError(
        `Synthesizing ethical decision failed: ${errorMessage}`,
        {
          originalError: error,
          modelName: config.llmModel,
          prompt: String(prompt).substring(0, 500) + "...",
        },
      );
    }
  }
}
